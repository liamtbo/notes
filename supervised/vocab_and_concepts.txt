bias
    error introduced by trying to approximate complex real-world problems with a simplified model
    high bias
        underfitting
        using linear regression to approximate data that has a non-linear relationship
    low bias
        overfitting

bias-variance trade off
    increasing model complexity generally decreases bias but increases variance and vice versa
    high bias, low variance
        simple models (linear regression) typically have a high bias and low variance because they are stable but may not capture the complexity of the data
    low bias, high variance
        complex models (deep decision trees, nn) tend to have low biad but high variance, which means they can model the training data well but might not generalize to new data

cross validation
    allows us to compare different machine learning methods and get a dense of how well they will work in practice
    trains model on first 75%, tests with last 25% of data
    trains model on first 50% and last 25%, tests with middle 25% of data
    trains model on first 25% and last 75%, tests with middle 25% of data
    trains model on first 25%, tests with last 75% of data
    do this with all methods (logistic regression, SVM, K-nearest neighbors)
    chose methods with best cumulative results of tests
    
    ten-fold cross validation most common
    can also be used for tuning hyper params

ensemble methods
    ensemble is a group of elementes viewed as a whole rather than individually.
    ensemble method creates multiple models and combines them to solve a problem

variance
    the model's sensitivity to small fluctation in the training data
    high variance
        overfitted
        model learned the noise in the training set and output changes durastically with changes in data set


